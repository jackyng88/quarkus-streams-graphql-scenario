---
title: Quarkus, MP Reactive Messaging, Kafka Streams, GraphQL and VueJS
description: Using Kafka Streams to process streams for consumption with a GraphQL API Server
---

<AnchorLinks>
    <AnchorLink>Overview</AnchorLink>
    <AnchorLink>Scenario Prerequisites</AnchorLink>
    <AnchorLink>Bootstrapping the Quarkus Application</AnchorLink>
    <AnchorLink>Adding a MicroProfile Reactive Messaging Producer to the Quarkus Application</AnchorLink>
    <AnchorLink>Creating the WebSocket Server</AnchorLink>
    <AnchorLink>Creating the Kafka Streams Topology</AnchorLink>
    <AnchorLink>Creating the Database</AnchorLink>
    <AnchorLink>Creating the GraphQL API Server</AnchorLink>
    <AnchorLink>Testing the GraphQL API Server</AnchorLink>
    <AnchorLink>Creating the GraphQL Client Application with VueJS and Vue-Apollo</AnchorLink>
    <AnchorLink>Using the Entire Application</AnchorLink>
</AnchorLinks>

![Technologies](./images/quarkus-kafka-graphql-vue-diagram.png)

## Overview
- This scenario will show how we can leverage several technologies in tandem with the capabilities of Kafka,
and more specifically Kafka Streams.
- We will use Quarkus for most of the backend functionality. It will be used for our mock producer to produce events, 
for streams processing with our Kafka Streams topology, to create a WebSocket server and lastly to push those events from
Kafka Streams onto said WebSocket Server.
- A GraphQL API Server will be created using Node (Apollo Server)
- The database for which the GraphQL API will hook up to will use Sequelize (Node-based ORM for various DBMS) using a local SQLite store, and Apollo-Server.
- A "frontend" component that using VueJS will serve two functions. Through Vue (and mostly Javascript) we will connect to 
the WebSocket and read messages. Vue-Apollo will then be used to query and perform mutations through the GraphQL API Server.


## Scenario Prerequisites
**Java**
- Java 8+

**Maven**
- Maven will be needed for bootstrapping our application from the command-line and running
our Quarkus backend (mock producer, Kafka Streams topology, and WebSocket server) application.

**Node**
- We will need Node.js and more specifically npm for not only the GraphQL Server but for VueJS as well.

**VueJS CLI**
- If you don't already have it installed as long as you have npm you can install it with the following command:

```shell
npm install -g @vue/cli
```

*The following are optional, you can tailor this to use a local Kafka cluster*

**OpenShift Container Platform**
- v4.4.x

**IBM Cloud Pak for Integration**
- CP4I2020.2.1

**IBM Event Streams**
- The section on use with Event Streams on CP4I assumes Event Streams v10. IF using a previous version such as ESv2019.4.2
there are some differences to how you would configure `application.properties` to establish a connection.


## Bootstrapping the Quarkus Application

- Let's use the Maven CLI to bootstrap our Quarkus project which we will use for our Kafka needs. Replace `{xxxxx}` with 
your choosing.

```shell
mvn io.quarkus:quarkus-maven-plugin:1.10.2.Final:create \
    -DprojectGroupId={com.ibm} \
    -DprojectArtifactId={quarkus-kstreams-graphql} \
    -Dextensions="kafka,kafka-streams,resteasy-jsonb,quarkus-kafka-streams,undertow-websockets"
```
- Now that we have our project, we need to first create our Plain Old Java Object (POJO) class which will be used as the basis
for how our events will be serialized and deserialized. Create the following folder structure as well as the class. Again make 
sure that what comes after `src/main/java/xxx/xxxx` is of your choosing.

`src/main/java/com/ibm/domain/Scores.java`

- Paste the following content.

```java
package com.ibm.domain;

public class Scores {

    public String scoreId;
    public int awayTeamId;
    public int homeTeamId;
    public int awayTeamScore;
    public int homeTeamScore;
    public int quarter;
    public int time;
    public boolean gameComplete;

    public Scores() {

    }

    public Scores(String scoreId, int awayTeamId, int homeTeamId, int awayTeamScore, 
                  int homeTeamScore, int quarter, int time, boolean gameComplete) {

        this.scoreId = scoreId;
        this.awayTeamId = awayTeamId;
        this.homeTeamId = homeTeamId;
        this.awayTeamScore = awayTeamScore;
        this.homeTeamScore = homeTeamScore;
        this.quarter = quarter;
        this.time = time;
        this.gameComplete = gameComplete;
    }
}
```

- Great we now have our base Quarkus application.

## Adding a MicroProfile Reactive Messaging Producer to the Quarkus Application

- The basis for the Quarkus application is created and now we need some way to generate events/data to the Kafka Topic. Create 
the Producer java file along with the infrastructure folder like so -

`src/main/java/com/ibm/infrastructure/Producer.java`

- Paste the following into the `Produer.java` file - 

```java
package com.ibm.infrastructure;

import java.util.Random;
import java.util.concurrent.TimeUnit;

import javax.enterprise.context.ApplicationScoped;

import org.eclipse.microprofile.reactive.messaging.Outgoing;

import io.reactivex.Flowable;
import io.smallrye.reactive.messaging.kafka.KafkaRecord;

import com.ibm.domain.*;


@ApplicationScoped
public class Producer {
    // Start a game between an away team and an home team. Starts at 1st quarter, and 12 minutes (720 seconds) for time.
    // This producer will constantly decrement the time/update the score. When the time reaches 00:00 the quarter
    // will increment. When the game reaches the 4th quarter and 00:00, the game is completed.

    Scores mockScore = new Scores("0", 1, 2, 0, 0, 1, 720, false);
    private Random random = new Random();

    @Outgoing("mock-messages")
    public Flowable<KafkaRecord<String, Scores>> produceMock() {
        return Flowable.interval(5, TimeUnit.SECONDS)
                       .map(tick -> {
                            return runGame(mockScore);
                        });
    }

    public KafkaRecord<String, Scores> runGame(Scores mock) {
        
        if (mock.quarter < 5 && mock.time > 0) {
            mock.time -= 20;
            mock.awayTeamScore = calculateScore(mock.awayTeamScore);
            mock.homeTeamScore = calculateScore(mock.homeTeamScore);

            if (mock.quarter < 4 && mock.time == 0) {
                mock.quarter += 1;
                mock.time = 720;
            }
        }

        // Game is finished
        if (mock.quarter == 4 && mock.time == 0) {
            mock.gameComplete = true;
        }

        return KafkaRecord.of(mock.scoreId, mock);
    }

    public int calculateScore (int score) {
        // randomly choose between a two pointer or a three pointer.
        // Then calculate with a percentage. 0 for two pointer, 1 for three.
        // Two is 45% and three is 32%. 
        int points = 0;
        int shotSelection = random.nextInt(2);
        float shotPercentage = random.nextFloat();

        if (shotSelection == 0) {
            if (shotPercentage <= 0.45) {
                points = 2;
            }
        }

        else if (shotSelection == 1) {
            if (shotPercentage <= 0.32) {
                points = 3;
            }
        }

        return score + points;
    }
}
```
- Explanation of a few key components:
    - We create a `mockScore` Scores object with a few values.
    - `@Outgoing("mock-messages")` is how MP Reactive Messaging will produce events. The `Outgoing` annotation does what it sounds
    like. There's an `Incoming` annotation for consuming as well. In this example `"mock-messages"` is the name of the Channel and is
    how it knows where to produce messages to. By default with the Kafka connector, the name of the Kafka topic that will be used is the 
    name of the Channel, but you can specify this to your liking in the `application.properties` file that we will get to later.
    - The return of the `produceMock()` function is a RxJava2 Flowable wrapped around a KafkaRecord with key String and Value being
    a Scores object. 

- We will now need to update our `application.properties` files so that our Quarkus application will have the proper configurations
to connect to the various systems. Go to `src/main/resources/application.properties` and paste the following: 

```properties
quarkus.http.port=8085
quarkus.log.console.enable=true
quarkus.log.console.level=INFO

# Base Reactive Messaging Connection Details (with security for ESv10)
mp.messaging.connector.smallrye-kafka.bootstrap.servers=${BOOTSTRAP_SERVERS}
mp.messaging.connector.smallrye-kafka.security.protocol=SASL_SSL
mp.messaging.connector.smallrye-kafka.ssl.protocol=TLSv1.2
mp.messaging.connector.smallrye-kafka.sasl.mechanism=SCRAM-SHA-512
mp.messaging.connector.smallrye-kafka.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
                username=${SCRAM_USERNAME} \
                password=${SCRAM_PASSWORD};
mp.messaging.connector.smallrye-kafka.ssl.truststore.location=${CERT_LOCATION}
mp.messaging.connector.smallrye-kafka.ssl.truststore.password=${CERT_PASSWORD}
mp.messaging.connector.smallrye-kafka.ssl.truststore.type=PKCS12

# Initial mock JSON message producer configuration
mp.messaging.outgoing.mock-messages.connector=smallrye-kafka
mp.messaging.outgoing.mock-messages.topic=${START_TOPIC_NAME}
mp.messaging.outgoing.mock-messages.group.id=scores-mock-producer
mp.messaging.outgoing.mock-messages.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer


# Quarkus Kafka Streams configuration settings (with security for ESv10)
quarkus.kafka-streams.bootstrap-servers=${BOOTSTRAP_SERVERS}
quarkus.kafka-streams.application-id=websocket-stream-local
quarkus.kafka-streams.application-server=localhost:8085
quarkus.kafka-streams.topics=${START_TOPIC_NAME},${ONGOING_TOPIC_NAME},${COMPLETE_TOPIC_NAME}
quarkus.kafka-streams.health.enabled=true
quarkus.kafka-streams.security.protocol=SASL_SSL
quarkus.kafka-streams.ssl.protocol=TLSv1.2
quarkus.kafka-streams.sasl.mechanism=SCRAM-SHA-512
quarkus.kafka-streams.sasl.jaas.config=org.apache.kafka.common.security.scram.ScramLoginModule required \
                username=${SCRAM_USERNAME} \
                password=${SCRAM_PASSWORD};
quarkus.kafka-streams.ssl.truststore.location=${CERT_LOCATION}
quarkus.kafka-streams.ssl.truststore.password=${CERT_PASSWORD}
quarkus.kafka-streams.ssl.truststore.type=PKCS12


# pass-through options
kafka-streams.cache.max.bytes.buffering=10240
kafka-streams.commit.interval.ms=1000
kafka-streams.metadata.max.age.ms=500
kafka-streams.auto.offset.reset=latest
kafka-streams.metrics.recording.level=DEBUG
```

- The top half with properties prefixed with `mp.messaging.connector.smallrye-kafka.` is what we're currently implementing. 
    - The first chunk is for actual connection to an IBM Event Streams v10 instance by providing bootstrap and various security certificates.
    - `mp.messaging.outgoing.mock-messages.topic` is how we're changing our Channel from our `Outgoing` annotation earlier to use a specific 
    Kafka topic name instead of just the Channel name which is `mock-messages` in this example. 
    - a `group.id` is provided for uniqueness.
    - the `value.serializer` property is provided by using the resteasy JsonbSerializer for serializing our records into JSON format.
    - If you are trying to connect to a local Kafka Cluster you can remove the security options i.e. the `ssl` and `sasl` prefixes.
    `mp.messaging.connector.smallrye-kafka.ssl.*` and `quarkus.kafka-streams.ssl.*` for example.

- Most of the `quarkus.kafka-streams.` settings are self-explanatory enough due to their similary to the MP Reactive Messaging ones 
but we will talk about that in a bit.


## Creating the WebSocket Server

- We have the first portion of the scenario where we are producing events to a Kafka Topic. Before we can implement our
Kafka Streams topology that will send those messages to a WebSocket Server... we need to first create said WebSocket. For that
we will be using Undertow WebSockets.

- Create a new file named `OngoingWebSocketServer.java` within `src/main/com/ibm/java/infrastructure`. 
You can of course name this to something else. Paste the following content: 

```java
package com.ibm.infrastructure;

import java.util.Collections;
import java.util.Set;
import java.util.concurrent.ConcurrentHashMap;

import javax.enterprise.context.ApplicationScoped;
import javax.websocket.CloseReason;
import javax.websocket.OnClose;
import javax.websocket.OnOpen;
import javax.websocket.Session;
import javax.websocket.server.ServerEndpoint;

import org.slf4j.Logger;
import org.slf4j.LoggerFactory;


@ServerEndpoint("/ongoing")
@ApplicationScoped
public class OngoingWebSocketServer {

    private static final Logger LOG = LoggerFactory.getLogger( OngoingWebSocketServer.class );

    private static final Set<Session> sessions = Collections.newSetFromMap( new ConcurrentHashMap<>() );

    @OnOpen
    public void open(Session session) {
        LOG.info( "Opening session: " + session.getId() );
        sessions.add(session);
    }

    @OnClose
    public void close(Session session, CloseReason c) {
        sessions.remove( session );
        LOG.info( "Closing: " + session.getId() );
    }

    public Set<Session> getSessions() {
        return sessions;
    }
}
```

- Key things of note:
    - With the `@ServerEndpoint` annotation, this will append the field onto WebSocket URI. For example if our application
    server is running on `localhost:8085` then the WS URI will be at `ws://localhost:8085/ongoing/`. 
    - Sessions are added onto a hash map on connection and removed with close.
    - The actual writing to the WebSocket will be done in our Kafka Streams topology a bit later.

- Our WebSocket Server is now setup.


## Creating the Kafka Streams Topology

- We have the first two major portions of the Quarkus application made and now we need arguably the most important, the Kafka Streams
topology. This will be responsible for getting our events from the Kafka Topic, process them, and then off they go to the WebSocket.

- Create the `BasketballTopology.java` file which you can name whatever you would like inside `src/main/java/com/ibm/domain/` and 
paste the following:

```java
package com.ibm.domain;

import java.io.IOException;

import javax.enterprise.context.ApplicationScoped;
import javax.enterprise.inject.Produces;
import javax.inject.Inject;

import org.eclipse.microprofile.config.inject.ConfigProperty;

import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.Topology;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.Produced;

import io.quarkus.kafka.client.serialization.JsonbSerde;

import com.fasterxml.jackson.databind.ObjectMapper;
import com.ibm.infrastructure.*;


@ApplicationScoped
public class BasketballTopology {

    // The topology will have a KStream for the constantly updating game score, it will then 
    // do a join by teamId on a KTable and enrich the message with the teamNames. It will then
    // output this to a topic.
    @ConfigProperty(name = "START_TOPIC_NAME")
    private String INCOMING_TOPIC;

    @ConfigProperty(name = "ONGOING_TOPIC_NAME")
    private String ONGOING_TOPIC;

    @ConfigProperty(name = "COMPLETE_TOPIC_NAME")
    private String COMPLETE_TOPIC;

    @Inject
    OngoingWebSocketServer ongoingEndPoint;

    @Produces
    public Topology buildTopology() {

        StreamsBuilder builder = new StreamsBuilder();

        JsonbSerde<Scores> scoresSerde = new JsonbSerde<>(Scores.class);

        ObjectMapper obj = new ObjectMapper();

        KStream<String, Scores> ongoingScoresStream = builder.stream(
            INCOMING_TOPIC,
            Consumed.with(Serdes.String(), scoresSerde)
        );
        
        KStream<String, Scores>[] branches = ongoingScoresStream.branch(
            (key, scores) -> scores.gameComplete,
            (key, scores) -> !scores.gameComplete
        );

        branches[0].to(
            COMPLETE_TOPIC,
            Produced.with(Serdes.String(), scoresSerde)
        );

        branches[1].peek((key, scores) -> {
            ongoingEndPoint.getSessions().forEach(s -> {
                try {
                    s.getBasicRemote().sendText(obj.writeValueAsString(scores));
                }
                catch (IOException e) {
                    throw new RuntimeException(e);
                }
            });
        });

        branches[1].to(
            ONGOING_TOPIC,
            Produced.with(Serdes.String(), scoresSerde)
        );

        return builder.build();
    }
}
```

- Some key things to note:
    - We will be using environment variables to supply the values of our topic names thus the `@configProperty` annotations.
    - We perform a dependency injection with the `@Injection` annotation on a new `OngoingWebSocketServer`.
    - The Kafka Streams DSL API is being used with StreamsBuilder.
    - A scoresSerde is created for the purposes of serializing and deserializing Scores objects wrapped with the JsbonSerde class.
    - The `ongoingScoresStream` KStream is created by consuming from `INCOMING_TOPIC` with a String key serde and a Scores value serde. 
    - Next, we branch the stream. `branches[0]` will get events/records where the `gameComplete` boolean flag is true and `branches[1]` will get
    them with false (meaning game is not complete).
    - `branches[0]` will be produced and persisted with `COMPLETE_TOPIC`.
    - `branches[1]` will have events streamed where games are incomplete. We use the `peek` operator to send these events to our WebSocket server.
    Our `Scores` POJO is converted to String and then sent to each session connected to the WebSocket. Lastly, this stream is also
    sent to an `OUTGOING_TOPIC` for persistence.

- Great! We're now done with the Quarkus portion. 

- **TO-DO** Add more functionality to the topology for enrichment.


## Creating the Database

- Let's start by creating a new folder inside the root directory for our Node project. You can name the project whatever you like.
`quarkus-kstreams-graphql/graphql-server/`

```shell
mkdir graphql-server
cd graphql-server
npm init -y
```

- Now we need to add the Node packages we'll need.

```shell
npm install sequelize sequelize-cli sqlite3 --save
```

- We will now need to use the Sequelize CLI to help scaffold out the project.

```shell
node_modules/.bin/sequelize init
```

- The following folders will be created.
    - `config`: contains a configuration file will help Sequelize with the connection to the database.
    - `models`: contains all models for the project. An index.js file which will integrate the models together.
    - `migrations`: contains all migration files.
    - `seeders`: contains all seed files.

- Open `config/config.json` and replace it with the following content

```json
// config/config.json

{
  "development": {
    "dialect": "sqlite",
    "storage": "./database.sqlite"
  }
}
```

- What this file means is that the `dialect` is our Database of choice and `storage` is the location
of our store.

- Next, create the database file.

```shell
touch database.sqlite
```

- Now that we have our initial database setup we can move to creating our models and migrations. Let's use 
the Sequelize CLI to create a `Scores` model.

```shell
node_modules/.bin/sequelize model:create --name Scores --attributes scoresId:string,awayTeamId:integer,homeTeamId:integer,awayTeamScore:integer,homeTeamScore:integer,quarter:integer,time:integer,gameComplete:boolean
```

- This will create a `scores.js` file inside the `models` folder as well as a `migrations` file. Open our migrations file
inside `migrations/XXXXXXXXX-create-scores.js`. We need to make sure that our `scoresId` field is our primary key as well as the other fields
being un-nullable.

```js
// migrations/XXXXXXXXX-create-scores.js

'use strict';
module.exports = {
  up: async (queryInterface, Sequelize) => {
    await queryInterface.createTable('Scores', {
      scoresId: {
        type: Sequelize.STRING,
        allowNull: false,
        primaryKey: true
      },
      awayTeamId: {
        allowNull: false,
        type: Sequelize.INTEGER
      },
      homeTeamId: {
        allowNull: false,
        type: Sequelize.INTEGER
      },
      awayTeamScore: {
        allowNull: false,
        type: Sequelize.INTEGER
      },
      homeTeamScore: {
        allowNull: false,
        type: Sequelize.INTEGER
      },
      quarter: {
        allowNull: false,
        type: Sequelize.INTEGER
      },
      time: {
        allowNull: false,
        type: Sequelize.INTEGER
      },
      gameComplete: {
        allowNull: false,
        type: Sequelize.BOOLEAN
      },
      createdAt: {
        allowNull: false,
        type: Sequelize.DATE
      },
      updatedAt: {
        allowNull: false,
        type: Sequelize.DATE
      }
    });
  },
  down: async (queryInterface, Sequelize) => {
    await queryInterface.dropTable('Scores');
  }
};
```

- We will need to update the `scores.js` model as well.

```js
// models/scores.js

'use strict';
const {
  Model
} = require('sequelize');
module.exports = (sequelize, DataTypes) => {
  class Scores extends Model {
    /**
     * Helper method for defining associations.
     * This method is not a part of Sequelize lifecycle.
     * The `models/index` file will call this method automatically.
     */
    static associate(models) {
      // define association here
    }
  };
  Scores.init({
    scoresId: {
      type: DataTypes.STRING,
      primaryKey: true
    },
    awayTeamId: DataTypes.INTEGER,
    homeTeamId: DataTypes.INTEGER,
    awayTeamScore: DataTypes.INTEGER,
    homeTeamScore: DataTypes.INTEGER,
    quarter: DataTypes.INTEGER,
    time: DataTypes.INTEGER,
    gameComplete: DataTypes.BOOLEAN
  }, {
    sequelize,
    modelName: 'Scores',
  });
  return Scores;
};
```

- Run the migrations

```shell
node_modules/.bin/sequelize db:migrate
```


- **TO-DO** After implementing a many-to-many join for the Kafka Streams topology for data enrichment will need to 
create another model and specify relationships (and inverse relationships) between the new models.


## Creating the GraphQL API Server

- Now that we have our database set up it's time to create the GraphQL API Server using Apollo Server. install
the necessary packages.

```shell
npm install apollo-server graphql --save
```

- Once done let's create a `src` folder as well as an `index.js` file with the following content.

```js
// src/index.js

const { ApolloServer } = require('apollo-server')
const typeDefs = require('./schema')
const resolvers = require('./resolvers')
const models = require('../models')

const server = new ApolloServer({
  typeDefs,
  resolvers,
  context: { models }
})

server
  .listen()
  .then(({ url }) => console.log('Server is running on localhost:4000'))
```

- Here, we create a new instance of Apollo Server. We then pass to it schema and resolvers (both which we’ll create shortly). 
We also pass the models as the context to the Apollo Server. This will allow us to have access to the models from our resolvers.

### GraphQL Schema 

*A GraphQL schema is used to define the functionality a GraphQL API would have. A GraphQL schema is comprised of 
a hierarchy of types with fields that are populated from your back-end data stores. The schema also outlines what
functionality (queries, mutations, subscriptions) the clients will have access to when executing against your GraphQL Server. *


- Time to define our GraphQL Schema. Create `schema.js` within the `src` folder.

```js
// src/schema.js

const { gql } = require('apollo-server')

const typeDefs = gql`
    type Scores {
        scoresId: String!
        awayTeamId: Int!
        homeTeamId: Int!
        awayTeamScore: Int!
        homeTeamScore: Int!
        quarter: Int!
        time: Int!
        gameComplete: Boolean!
      }

    type Query {
        score(scoresId: String!): Scores
        allScores: [Scores!]!
    }

    type Mutation {
        createScores(
          scoresId: String!
          awayTeamId: Int!
          homeTeamId: Int!
          awayTeamScore: Int!
          homeTeamScore: Int!
          quarter: Int!
          time: Int!
          gameComplete: Boolean!
          ): Scores!

        deleteScores(scoresId: String!): String

        updateScores(
          scoresId: String!
          awayTeamId: Int!
          homeTeamId: Int!
          awayTeamScore: Int!
          homeTeamScore: Int!
          quarter: Int!
          time: Int!
          gameComplete: Boolean!
          ): String

    type Subscription {
        scoresUpdated: Scores
      }
        
    }
`

module.exports = typeDefs

```

- As you can tell this was written in gql or graph query language. We want to mirror our database as much as possible
so our types reflect that. Within the types we specify `Query` and `Mutation` for executions against our GraphQL API Server.


- It's time to create the `resolvers`. Resolvers define how the fields in a schema are executed.
Create a `resolvers.js` file inside the `src` directory and add the following code in it:

```js
// src/resolvers.js

const { PubSub } = require('apollo-server')

const pubsub = new PubSub();

const resolvers = {
    
    Query: {
        async score (root, { scoresId }, { models }) {
              return models.Scores.findByPk(scoresId)
        },
        async allScores (root, args, { models }) {
              return models.Scores.findAll()
        }
    },
    
    Mutation: {
        async createScores (root, { scoresId, awayTeamId, homeTeamId, awayTeamScore,
                                   homeTeamScore, quarter, time, gameComplete }, { models }) {
            return models.Scores.create({
                scoresId,
                awayTeamId,
                homeTeamId,
                awayTeamScore,
                homeTeamScore,
                quarter,
                time,
                gameComplete
              })
        },
        async deleteScores(root, { scoresId }, { models }) {
            //const id = scoresId
            models.Scores.destroy({
                where: {
                    scoresId: scoresId
                }
            })

            return `Score with ID: ${scoresId} deleted`
        },
        async updateScores(root, { scoresId, awayTeamId, homeTeamId, awayTeamScore,
                                   homeTeamScore, quarter, time, gameComplete }, { models }) {
                models.Scores.update({ 
                    awayTeamId: awayTeamId,
                    homeTeamId: homeTeamId,
                    awayTeamScore: awayTeamScore,
                    homeTeamScore: homeTeamScore,
                    quarter: quarter,
                    time: time,
                    gameComplete: gameComplete
                },
                {
                    where: {
                        scoresId: scoresId
                    }
                }  
            )

            pubsub.publish("scoreUpdated", { scoresUpdated: { scoresId, awayTeamId, homeTeamId, awayTeamScore,
                                                             homeTeamScore, quarter, time, gameComplete } });
            return `Score with ID: ${scoresId} updated`
        }
    },

    Subscription: {
        scoresUpdated: {
            // Additional event labels can be passed to asyncIterator creation
            subscribe: () => pubsub.asyncIterator(["scoreUpdated"]),
          },
    },
}

module.exports = resolvers


```
- Things of note:
    - The `score` mutation does a single lookup within our model context by primary key and `allScores` is basically a `select * from Scores`.
    The `createScores` mutation accepts all the fields and creates a new record in the database with the supplied details. 
    It will then return the newly created user. `updateScores` mutation will update all the fields matching the provided scoresId. 
    The equivalent of a SQL statement such as an update where scoresId = x. 
    - We're adding `pubsub` functionality so we can properly use subscriptions. When the `updateScores` mutation is called
    it publishes that event and the subscription `scoresUpdated` will receive it on the `"scoreUpdated"` channel for specificity.


- **TO-DO** Will need to update resolvers.js to accomodate for the relationships between future models.


## Testing the GraphQL API Server

- Start the GraphQL API Server with the following command:

```shell
node src/index.js
```

- Open `localhost:4000` and let's test out the functionality of the GraphQL API.

```gql
mutation {
  createScores(
    scoresId: "0"
    awayTeamId: 1
    homeTeamId: 2
    awayTeamScore: 0
    homeTeamScore: 0
    quarter: 1
    time: 720
    gameComplete: false
  ) {
    scoresId
    awayTeamId
    homeTeamId
    awayTeamScore
    homeTeamScore
    quarter
    time
    gameComplete
  }
}
```

- Submit the mutation and you should see the following result.

![GraphQL Mutation](./images/graphql-mutation.png)


## Creating the GraphQL Client Application with VueJS and Vue-Apollo

- We have all the building blocks of the scenario now - a mock producer sending events to a Kafka Topic, a Kafka Streams Topology 
that will process and stream events to a WebSocket server, a local SQLite database, and a GraphQL API Server that will perform
queries on mutations backed with said SQLite database. We will now have a VueJS application that will handle the client side connection
and process messages received from the WebSocket. With Vue-Apollo it will either perform a `createScores` mutation or an `updateScores`
mutation depending on if the query with `scoresId` primary key returns null or not.

- Now go back to the root of our `quarkus-kstreams-graphql` project folder. Bootstrap our Vue application with the following command. Again
you can replace `{vue}` with a name of your choosing but I will be using `vue` for simplicity's sake.

```shell
vue create {vue}
```

- Choose the default settings.

![Vue CLI](./images/vue-cli.png)

- Change directories into the newly created Vue project.

```shell
cd vue
```

- You can test the newly created boilerplate Vue project by going to `localhost:8080` after running:

```shell
npm run serve
```

- Now we need to install the necessary dependencies for our Vue project for use with GraphQL.

```shell
npm install apollo-link-ws apollo-boost apollo-client apollo-link-http apollo-cache-inmemory vue-apollo graphql graphql-tag --save
```

- Now open `src/main.js` file and paste the following: 

```js
import { InMemoryCache } from 'apollo-cache-inmemory'
import { ApolloClient } from 'apollo-client'
import { split } from 'apollo-link'
import { HttpLink } from 'apollo-link-http'
import { WebSocketLink } from 'apollo-link-ws'
import { getMainDefinition } from 'apollo-utilities'
import Vue from 'vue'
import VueApollo from 'vue-apollo'
import App from './App.vue'

Vue.config.productionTip = false

const httpLink = new HttpLink({
    uri: 'http://localhost:4000/graphql'
})

const wsLink = new WebSocketLink({
    uri: 'ws://localhost:4000/graphql',
    options: {
      reconnect: true,
      lazy: true
    }
})

wsLink.subscriptionClient.on('connecting', () => {
  console.log('connecting');
});

wsLink.subscriptionClient.on('connected', () => {
  console.log('connected');
});

wsLink.subscriptionClient.on('reconnecting', () => {
  console.log('reconnecting');
});

wsLink.subscriptionClient.on('reconnected', () => {
  console.log('reconnected');
});

wsLink.subscriptionClient.on('disconnected', () => {
  console.log('disconnected');
});

wsLink.subscriptionClient.maxConnectTimeGenerator.duration = () =>
  wsLink.subscriptionClient.maxConnectTimeGenerator.max;

const link = split(
    ({ query }) => {
      const definition = getMainDefinition(query);
      return (
        definition.kind === "OperationDefinition" &&
        definition.operation === "subscription"
      );
    },
    wsLink,
    httpLink
)

const apolloClient = new ApolloClient({
    link,
    cache: new InMemoryCache(),
    connectToDevTools: true
})

const apolloProvider = new VueApollo({
    defaultClient: apolloClient
})

Vue.use(VueApollo)

new Vue({
    apolloProvider,
    render: h => h(App)
}).$mount('#app')
```

- Things of note:
    - The URI that the `httpLink` is connecting to is the GraphQL API Server we created at `localhost:4000/graphql`
    - `wsLink` is the URI for our WebSocket server that our Apollo Client will later need to connect to for subscriptions.
    - `link` is called with the `split` function to separate the URI endpoints that we're using. Queries and mutations will go to 
    `httpLink` and subscriptions will go to `wsLink`.
    - We're mounting the `App.vue` component file to be rendered.

- We now need to handle the connection to WebSocket as well as the messages. Create a new file in the `src` folder named
`socket.js`

```js
// src/socket.js

import Vue from "vue"

const socket = new WebSocket("ws://localhost:8085/ongoing")

const emitter = new Vue({
    data() {
        return {
            parsed: []
        }
    },
    methods: {
        send(message) {
            if (1 === socket.readyState)
                socket.send(message)
        }
    }
})

socket.onmessage = function (msg) {
    this.parsed = JSON.parse(msg.data)
    emitter.$emit("message", this.parsed)
}
socket.onerror = function (err) {
    emitter.$emit("error", err)
}


export default emitter

```

- Things of note:
    - Connection is established to the WebSocket via `ws://localhost:8085/ongoing` with the `socket` object.
    - When a connection is established `send` is invoked.
    - The data from the message is changed into JSON and them emitted for use.


- Time to update our `App.vue` component file in the `src` folder. Paste the following: 

```vue
<template>
  <div id="app">
    <h2>Vue.js Kafka Streams GraphQL Test</h2>

    <table border="1" width="100%" style="border-collapse: collapse;">
      <tr>
        <th>scoresId</th>
        <th>awayTeamId</th>
        <th>homeTeamId</th>
        <th>awayTeamScore</th>
        <th>homeTeamScore</th>
        <th>quarter</th>
        <th>time</th>
        <th>gameComplete</th>
      </tr>

      <tr v-bind:key="score.scoresId" v-for="score in allScores">
        <td>{{ score.scoresId }}</td>
        <td>{{ score.awayTeamId }}</td>
        <td>{{ score.homeTeamId }}</td>
        <td>{{ score.awayTeamScore }}</td>
        <td>{{ score.homeTeamScore }}</td>
        <td>{{ score.quarter }}</td>
        <td>{{ score.time }}</td>
        <td>{{ score.gameComplete }}</td>
      </tr>
    </table>
  </div>
</template>

<script>
import Socket from "./socket";
import { CREATE_SCORE } from "./queries/create_scores";
import { UPDATE_SCORES } from "./queries/update_scores";
import { GET_ALL_SCORES } from "./queries/all_scores";
import { GET_SINGLE_SCORE } from "./queries/get_single_score";
import { SCORES_SUBSCRIPTION } from "./queries/updated_scores_subscription";

export default {
  name: "App",
  data: function () {
    return {
      messages: [],
      connection: null,
      index: 0,
      scores: {},
      scoresId: "",
      awayTeamId: "",
      homeTeamId: "",
      awayTeamScore: "",
      homeTeamScore: "",
      quarter: "",
      time: "",
      gameComplete: false,
      allScores: {},
    };
  },
  apollo: {
    allScores: {
      query: GET_ALL_SCORES,
      subscribeToMore: {
        document: SCORES_SUBSCRIPTION,
        variables() {
          return {
            scoresId: this.scoresId,
          };
        },
        update(data) {
          return data.allScores;
        },
        updateQuery: (previousData, { subscriptionData }) => {
          const updatedScoreIndex = previousData.allScores.findIndex(
            (scores) =>
              scores.scoresId === subscriptionData.data.scoresUpdated.scoresId
          );

          const updatedScore = subscriptionData.data.scoresUpdated;
          const newAllScores = [...previousData.allScores];
          newAllScores[updatedScoreIndex] = updatedScore;
          const result = {
            ...previousData,
            allScores: newAllScores,
          };

          return result;
        },
      },
    },
  },
  methods: {
    async handleMessage(msg) {
      this.messages.push(msg);
      let idx = this.messages[this.messages.length - 1]["scoreId"];
      console.log("index is ", idx);
      const temp = await this.checkScores(idx);
      console.log(temp.data.score);

      if (temp.data.score === null) {

        this.createScores(msg);
      } 
      else {

        this.updateScores(msg);
      }
    },
    async checkScores(scoreId) {
      let score = this.$apollo.query({
        query: GET_SINGLE_SCORE,
        variables: {
          scoresId: scoreId,
        },
      });

      console.log("Checking score " + scoreId);

      return score;
    },

    updateScores(msg) {
      console.log(`Update score: # ${msg["scoreId"]}`);
      this.$apollo.mutate({
        mutation: UPDATE_SCORES,
        variables: {
          scoresId: msg["scoreId"],
          awayTeamId: msg["awayTeamId"],
          homeTeamId: msg["homeTeamId"],
          awayTeamScore: msg["awayTeamScore"],
          homeTeamScore: msg["homeTeamScore"],
          quarter: msg["quarter"],
          time: msg["time"],
          gameComplete: msg["gameComplete"],
        },
      });
    },
    createScores(msg) {
      console.log("Create score:", msg["scoreId"]);
      this.$apollo.mutate({
        mutation: CREATE_SCORE,
        variables: {
          scoresId: msg["scoreId"],
          awayTeamId: msg["awayTeamId"],
          homeTeamId: msg["homeTeamId"],
          awayTeamScore: msg["awayTeamScore"],
          homeTeamScore: msg["homeTeamScore"],
          quarter: msg["quarter"],
          time: msg["time"],
          gameComplete: msg["gameComplete"],
        },
      });
    },
  },
  created() {
    Socket.$on("message", this.handleMessage);
  },
  beforeDestroy() {
    Socket.$off("message", this.handleMessage);
  },
};
</script>

<style>
#app {
  font-family: Avenir, Helvetica, Arial, sans-serif;
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
  text-align: center;
  color: #2c3e50;
  margin-top: 60px;
}
</style>
```

- There's a lot here so let's break it down by sections.

### Template Section
- Not too much here besides that it's using a Vue directive known as `v-for` to iterate and dispaly with a list.
- `allScores` will be the GraphQL object that holds the all the returned data from the GraphQL query.

### Javascript Section
- We have 6 imports here. The first being the Socket from `socket.js` so we can properly use the WebSocket. The next 4
which we will create shortly are going to be the gql (graph query langage) queries that we will send.
- We have a `data` component which must be in the form of a function in Vue and thus must return. There are a few datatypes here 
to be used.
- Within the `apollo` we have an `allScores` object whose `query:` field is being called with `GET_ALL_SCORES`. Now to dive deeper you see
the `subscribeToMore` object which is how Vue Apollo will use subscriptions. Under `document:` we provide it the `SCORE_SUBSCRIPTION` gql 
subscription logic. The `update(data)` will return the object's store whereas `updateQuery:` object is being used to parsed for incoming fresh data.
It finds the proper `scoresId` of the record being updated and in essence creates an array clone and returns it with the old `allScores` query data
now with the reactive and freshly updating record at that `scoresId`. This allows us to see ALL the currently stored scores within the GraphQL
API Server as well as to see a reactive constantly updating view of the data via subscriptions.
- Next in `methods:` we have 4 functions - `handleMessage()`, `checkScores()`, `updateScores()`, and `createScores()`. The first two
of which are asynchronous functions. 
- In `handleMessage()` we're getting the `scoresId` primary key from the most recent message. The value of `temp` is invoked
by calling `await this.checkScores(idx)`. `checkScores()` will return a Promise and due to the asynchronous nature of it
we need to supply `await` before we can verify the actual data within the Promise. 
- `checkScores()` is an asychronous function that which will query the GraphQL API Server with the provided `scoresId` primary key.
- Next either `createScores()` or `updateScores()` functions are called depending on if the data within the Promise is null. If 
the data is null that means the query did not return data from the GraphQL API Server with that `scoresId` primary key.
- Lastly we have the `created()` and `beforeDestroy()` lifecycle hooks which are Vue's ways of mounting certain items to the DOM. 
When the Vue component is created and socket connection is established it calls `handleMessage()`.

- We now need to create our `gql` queries for use with our Apollo Client. Create a new folder in `src` named `queries`. We will need
to create 5 different Javascript files.

**`all_scores.js`**
```js
import gql from 'graphql-tag'

export const GET_ALL_SCORES = gql`query {
      allScores {
        scoresId,
        awayTeamId,
        homeTeamId,
        awayTeamScore,
        homeTeamScore,
        quarter,
        time,
        gameComplete
      }
    }`
```

**`get_single_score.js`**

```js
import gql from 'graphql-tag'

export const GET_SINGLE_SCORE = gql`query getScore($scoresId: String!) {
        score(scoresId: $scoresId) {
            scoresId,
            awayTeamId,
            homeTeamId,
            awayTeamScore,
            homeTeamScore,
            quarter,
            time,
            gameComplete
        }
    }`
```

**`create_scores.js`**
```js
import gql from 'graphql-tag'

export const CREATE_SCORE = gql`mutation createScores($scoresId: String!, $awayTeamId: Int! $homeTeamId: Int!, 
    $awayTeamScore: Int!, $homeTeamScore: Int!, $quarter: Int!, $time: Int! $gameComplete: Boolean!) {
        createScores(scoresId: $scoresId, awayTeamId: $awayTeamId, homeTeamId: $homeTeamId, awayTeamScore: $awayTeamScore, 
        homeTeamScore: $homeTeamScore, quarter: $quarter, time: $time, gameComplete: $gameComplete) {
            scoresId,
            awayTeamId,
            homeTeamId,
            awayTeamScore,
            homeTeamScore,
            quarter,
            time,
            gameComplete
    }
}`
```

**`update_scores.js`**
```js
import gql from 'graphql-tag'

export const UPDATE_SCORES = gql`mutation updateScores($scoresId: String!, $awayTeamId: Int! $homeTeamId: Int!, 
    $awayTeamScore: Int!, $homeTeamScore: Int!, $quarter: Int!, $time: Int! $gameComplete: Boolean!) {
        updateScores(scoresId: $scoresId, awayTeamId: $awayTeamId, homeTeamId: $homeTeamId, awayTeamScore: $awayTeamScore, 
        homeTeamScore: $homeTeamScore, quarter: $quarter, time: $time, gameComplete: $gameComplete) 
    }
`
```

**`updated_scores_subscription.js`**
```js
import gql from 'graphql-tag'

export const SCORES_SUBSCRIPTION = gql`subscription onScoreUpdate {
        scoresUpdated  {
            scoresId,
            awayTeamId,
            homeTeamId,
            awayTeamScore,
            homeTeamScore,
            quarter,
            time,
            gameComplete
        }
    }
`
```


## Using the Entire Application

- Start up the GraphQL API Server by going to the `graphql-server` folder under root.

```shell
node src/index.js
```

- Start the Vue components within the `vue` project folder.

```shell
npm run serve
```

- Before we start our Quarkus application for our producer and Kafka Streams topology we need to do a few 
environment variable exports. If you are using IBM Event Streams v10 you can get these connection details from the
`Connect to this Cluster` menu. Otherwise, you can forego the certificate and SCRAM credential variables in a local connection. 

```shell
export BOOTSTRAP_SERVERS=your-bootstrap-server-address:443 \
export START_TOPIC_NAME=name-of-topic-to-consume-from \
export ONGOING_TOPIC_NAME=name-of-topic-to-produce-to \
export COMPLETE_TOPIC_NAME=name-of-topic-for-complete-games \
export CERT_LOCATION=/path-to-pkcs12-cert/es-cert.p12 \
export CERT_PASSWORD=certificate-password \
export SCRAM_USERNAME=your-scram-username \
export SCRAM_PASSWORD=your-scram-password \
```

- Lastly, start the Quarkus application by in the root directory.

```shell
./mvnw quarkus:dev
```

- Go to your browser at `localhost:8080` to view the incoming messages. You can open the console to see the 
console logged messages. You can also manually run your queries directly at `localhost:4000`.
